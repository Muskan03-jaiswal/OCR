{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python numpy tensorflow deep_translator"
      ],
      "metadata": {
        "id": "IcwjrAH3x_Nw",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7665fb-e568-4cda-e206-4d6fb4bdf101"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting deep_translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.12/dist-packages (from deep_translator) (4.13.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.8)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep_translator\n",
            "Successfully installed deep_translator-1.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "id": "2SGTEWQpyCHb",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f2c0de0-95cf-47c4-828b-d2485631dee7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.49.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "trusted": true,
        "id": "oDuXIcOrn3Di",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e26a0e7-2e0e-47b7-b566-5e05364744a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.3.0\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppkC1UBOwklf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7a9bdf-5b4b-40cd-81e5-0f042e56eb75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from deep_translator import GoogleTranslator\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "def convert_2_gray(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    return gray_image\n",
        "\n",
        "def binarization(image):\n",
        "    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
        "    return thresh\n",
        "\n",
        "def dilate(image, words=False):\n",
        "    img = image.copy()\n",
        "    m = 3\n",
        "    n = m - 2\n",
        "    itrs = 4\n",
        "    if words:\n",
        "        m = 6\n",
        "        n = m\n",
        "        itrs = 3\n",
        "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (n, m))\n",
        "    dilation = cv2.dilate(img, rect_kernel, iterations=itrs)\n",
        "    return dilation\n",
        "\n",
        "def find_rect(image):\n",
        "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    rects = []\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        rects.append([x, y, w, h])\n",
        "    sorted_rects = sorted(rects, key=lambda x: x[0])\n",
        "    return sorted_rects\n",
        "\n",
        "# Assuming mapping_inverse is defined elsewhere\n",
        "mapping_inverse = {i: chr(i + 65) for i in range(26)}  # Example mapping (A-Z), adjust as needed\n",
        "\n",
        "def extract(image):\n",
        "    model = load_model('/content/CustomCnn_model.h5')\n",
        "    if model is None:\n",
        "        return None\n",
        "\n",
        "    chars = []\n",
        "    image_cpy = image.copy()\n",
        "    bin_img = binarization(convert_2_gray(image_cpy))\n",
        "    full_dil_img = dilate(bin_img, words=True)\n",
        "    words = find_rect(full_dil_img)\n",
        "\n",
        "    for word in words:\n",
        "        x, y, w, h = word\n",
        "        img = image_cpy[y:y+h, x:x+w]\n",
        "\n",
        "        bin_img = binarization(convert_2_gray(img))\n",
        "        dil_img = dilate(bin_img)\n",
        "        char_parts = find_rect(dil_img)\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
        "\n",
        "        for char in char_parts:\n",
        "            x, y, w, h = char\n",
        "            ch = img[y:y+h, x:x+w]\n",
        "\n",
        "            empty_img = np.full((32, 32, 1), 255, dtype=np.uint8)\n",
        "            x, y = 3, 3\n",
        "            resized = cv2.resize(ch, (16, 22), interpolation=cv2.INTER_CUBIC)\n",
        "            gray = convert_2_gray(resized)\n",
        "            empty_img[y:y+22, x:x+16, 0] = gray.copy()\n",
        "            gray = cv2.cvtColor(empty_img, cv2.COLOR_GRAY2RGB)\n",
        "            gray = gray.astype(np.int32)\n",
        "\n",
        "            predicted = mapping_inverse[np.argmax(model.predict(np.array([gray]), verbose=0))]\n",
        "            chars.append(predicted)\n",
        "        chars.append(' ')\n",
        "\n",
        "    return ''.join(chars[:-1]).lower()\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def translate_text(text, target_lang='en', source_lang='la'):\n",
        "    return GoogleTranslator(source=source_lang, target=target_lang).translate(text)\n",
        "\n",
        "def main():\n",
        "\n",
        "    st.title(\"Image Text Extraction and Translation App\")\n",
        "\n",
        "    # File uploader\n",
        "    uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read image\n",
        "        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
        "        image = cv2.imdecode(file_bytes, 1)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Display the uploaded image in the first column\n",
        "        st.image(image, caption=\"Uploaded Image\", use_container_width=False, width=300)\n",
        "\n",
        "        # Button for prediction (text extraction and translation)\n",
        "        if st.button('Predict'):\n",
        "            with st.spinner(\"Processing image...\"):\n",
        "                # Extract text from image\n",
        "                extracted_text = extract(image.copy())\n",
        "\n",
        "                if extracted_text:\n",
        "                    # Translate the extracted text\n",
        "                    translated_text = translate_text(extracted_text)\n",
        "\n",
        "                    # Display extracted and translated text below the image\n",
        "                    st.subheader(\"Extracted Text:\")\n",
        "                    st.write(extracted_text)\n",
        "\n",
        "                    st.subheader(\"Translated Text:\")\n",
        "                    st.write(translated_text)\n",
        "\n",
        "                    # Display success message\n",
        "                    st.success(\"Processing complete!\")\n",
        "                else:\n",
        "                    st.error(\"Failed to extract text from image\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multilanguage\n"
      ],
      "metadata": {
        "id": "Uirx9ZJxpBT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from deep_translator import GoogleTranslator\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "def convert_2_gray(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    return gray_image\n",
        "\n",
        "def binarization(image):\n",
        "    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
        "    return thresh\n",
        "\n",
        "def dilate(image, words=False):\n",
        "    img = image.copy()\n",
        "    m = 3\n",
        "    n = m - 2\n",
        "    itrs = 4\n",
        "    if words:\n",
        "        m = 6\n",
        "        n = m\n",
        "        itrs = 3\n",
        "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (n, m))\n",
        "    dilation = cv2.dilate(img, rect_kernel, iterations=itrs)\n",
        "    return dilation\n",
        "\n",
        "def find_rect(image):\n",
        "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    rects = []\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        rects.append([x, y, w, h])\n",
        "    sorted_rects = sorted(rects, key=lambda x: x[0])\n",
        "    return sorted_rects\n",
        "\n",
        "# Assuming mapping_inverse is defined elsewhere\n",
        "mapping_inverse = {i: chr(i + 65) for i in range(26)}  # Example mapping (A-Z), adjust as needed\n",
        "\n",
        "def extract(image):\n",
        "    model = load_model('/content/CustomCnn_model.h5')\n",
        "    if model is None:\n",
        "        return None\n",
        "\n",
        "    chars = []\n",
        "    image_cpy = image.copy()\n",
        "    bin_img = binarization(convert_2_gray(image_cpy))\n",
        "    full_dil_img = dilate(bin_img, words=True)\n",
        "    words = find_rect(full_dil_img)\n",
        "\n",
        "    for word in words:\n",
        "        x, y, w, h = word\n",
        "        img = image_cpy[y:y+h, x:x+w]\n",
        "\n",
        "        bin_img = binarization(convert_2_gray(img))\n",
        "        dil_img = dilate(bin_img)\n",
        "        char_parts = find_rect(dil_img)\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
        "\n",
        "        for char in char_parts:\n",
        "            x, y, w, h = char\n",
        "            ch = img[y:y+h, x:x+w]\n",
        "\n",
        "            empty_img = np.full((32, 32, 1), 255, dtype=np.uint8)\n",
        "            x, y = 3, 3\n",
        "            resized = cv2.resize(ch, (16, 22), interpolation=cv2.INTER_CUBIC)\n",
        "            gray = convert_2_gray(resized)\n",
        "            empty_img[y:y+22, x:x+16, 0] = gray.copy()\n",
        "            gray = cv2.cvtColor(empty_img, cv2.COLOR_GRAY2RGB)\n",
        "            gray = gray.astype(np.int32)\n",
        "\n",
        "            predicted = mapping_inverse[np.argmax(model.predict(np.array([gray]), verbose=0))]\n",
        "            chars.append(predicted)\n",
        "        chars.append(' ')\n",
        "\n",
        "    return ''.join(chars[:-1]).lower()\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def translate_text(text, source_lang, target_lang='en'):\n",
        "    return GoogleTranslator(source=source_lang, target=target_lang).translate(text)\n",
        "\n",
        "def main():\n",
        "    st.title(\"Image Text Extraction and Translation App\")\n",
        "\n",
        "    # Language selection dropdown\n",
        "    language_mapping = {\n",
        "        \"French\": \"fr\",\n",
        "        \"Spanish\": \"es\",\n",
        "        \"Latin\": \"la\",\n",
        "    }\n",
        "    selected_language = st.selectbox(\"Select source language:\", list(language_mapping.keys()))\n",
        "\n",
        "    # File uploader\n",
        "    uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read image\n",
        "        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
        "        image = cv2.imdecode(file_bytes, 1)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Display the uploaded image\n",
        "        st.image(image, caption=\"Uploaded Image\", use_container_width=False, width=300)\n",
        "\n",
        "        # Button for prediction (text extraction and translation)\n",
        "        if st.button('Predict'):\n",
        "            with st.spinner(\"Processing image...\"):\n",
        "                # Extract text from image\n",
        "                extracted_text = extract(image.copy())\n",
        "\n",
        "                if extracted_text:\n",
        "                    # Translate the extracted text\n",
        "                    translated_text = translate_text(extracted_text, language_mapping[selected_language])\n",
        "\n",
        "                    # Display extracted and translated text\n",
        "                    st.subheader(\"Extracted Text:\")\n",
        "                    st.write(extracted_text)\n",
        "\n",
        "                    st.subheader(\"Translated Text (English):\")\n",
        "                    st.write(translated_text)\n",
        "\n",
        "                    st.success(\"Processing complete!\")\n",
        "                else:\n",
        "                    st.error(\"Failed to extract text from image\")\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJGSsIKNo_c6",
        "outputId": "93dc3803-c94c-4928-a3fb-e8aab87d0d94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2uyxd5iqqp6c7W1yAa74n5KCcWI_7yMb1ap9YrjCS8tbHBiKx\")"
      ],
      "metadata": {
        "id": "19Ff6UmYusZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "f980aeaf-6f90-4f66-c07e-2e122e2a0118"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pyngrok'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1136740227.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyngrok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2uyxd5iqqp6c7W1yAa74n5KCcWI_7yMb1ap9YrjCS8tbHBiKx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyngrok'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_streamlit():\n",
        "  os.system('streamlit run /content/app.py --server.port 8000')"
      ],
      "metadata": {
        "id": "LQOTQTLsyebE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(\"2uyxd5iqqp6c7W1yAa74n5KCcWI_7yMb1ap9YrjCS8tbHBiKx\")\n"
      ],
      "metadata": {
        "id": "vzOdPjrJuyMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken'2uyxd5iqqp6c7W1yAa74n5KCcWI_7yMb1ap9YrjCS8tbHBiKx'"
      ],
      "metadata": {
        "id": "JltevAAtxPbg",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2128c1-5bfe-4e1c-a3f1-e6a1f584c7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME:\n",
            "  config - update or migrate ngrok's configuration file\n",
            "\n",
            "USAGE:\n",
            "  ngrok config [flags]\n",
            "\n",
            "DESCRIPTION: \n",
            "  The config command gives a quick way to create or update ngrok's configuration\n",
            "  file. Use 'add-authtoken' or 'add-api-key' to set the corresponding properties.\n",
            "\n",
            "  Use 'check' to test a configuration file for validity. If you have an old\n",
            "  configuration file, you can also use 'upgrade' to automatically migrate to the\n",
            "  latest version.\n",
            "\n",
            "COMMANDS:\n",
            "  add-api-key                    save api key to configuration file\n",
            "  add-authtoken                  save authtoken to configuration file\n",
            "  add-connect-url                adds the connect URL (connect_url) to configuration file for custom agent ingress\n",
            "  add-server-addr                alias of add-connect-url\n",
            "  check                          check configuration file\n",
            "  edit                           edit configuration file\n",
            "  upgrade                        auto-upgrade configuration file\n",
            "\n",
            "OPTIONS:\n",
            "      --config strings   path to config files; they are merged if multiple\n",
            "  -h, --help             help for config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread=Thread(target=run_streamlit)\n",
        "thread.start()\n",
        "\n",
        "public_url = ngrok.connect(addr='8000' ,proto='http',bind_tls=True)\n",
        "print(public_url)"
      ],
      "metadata": {
        "id": "o8nk7KQfxPX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49bbdaad-1e21-4479-8c94-b4cc65729878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://de48-35-199-55-163.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rX4ycfdszmUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def translate_text(text, target_lang='en', source_lang='la'):\n",
        "    return GoogleTranslator(source=source_lang, target=target_lang).translate(text)\n",
        "\n",
        "# Example usage\n",
        "input_text = \"QUOT RAMI TOT ARBORES\"\n",
        "translated = translate_text(input_text, target_lang='en')\n",
        "print(f\"Translated text: {translated}\")"
      ],
      "metadata": {
        "id": "zhL_dCtg2mpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcc20de-7a08-4ed2-c4d0-4f8f7164ca56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated text: How many branches are so many trees\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u46Y4YV23ADJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}